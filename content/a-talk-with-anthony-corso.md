+++
author = "Soham Patil"
categories = []
date = 2021-05-05T02:35:00Z
description = ""
draft = true
image = "/images/corso.jpg"
title = "A Talk with Anthony Corso"
type = "post"

+++
Anthony Corso is a post-doctorate researcher at the [Stanford Intelligent Systems Laboratory](http://sisl.stanford.edu/ "Stanford Intelligent Systems Laboratory"), a.k.a. SISL, pronounced "sizzle" :). He wrote his [PhD thesis](http://anthonylcorso.com/wp-content/uploads/2021/02/thesis.pdf "PhD thesis") about algorithms for black-box safety validation of autonomous vehicles, he's the executive director of the [Stanford Center for AI Safety](http://aisafety.stanford.edu/ "Stanford Center for AI Safety"), he wrote a deep reinforcement learning framework in Julia, and I recently got the chance to speak with him.

### Black-Box Safety Validation

Autonomous vehicles are being hyped more and more nowadays, but how can we ensure their safety? In this chunk of our conversation, we focused on one part of Anthony's thesis: finding relevant scenarios in which to test the vehicle. Anthony worked on a way to generate dangerous scenarios for these vehicles in simulations, so that their safety can be interpreted by humans.

### 